# FeelTrack-GenaritveAIFinalExam

# FeelTrack : CanlÄ± Duygu Analizi ve DanÄ±ÅŸmanlÄ±k Destek Sistemi


**FeelTrack**, gerÃ§ek zamanlÄ± sesli verilerden gelen konuÅŸmalarÄ± yazÄ±ya Ã§evirip duygusal analiz yaparak psikolojik Ã¶neriler sunan bir destek sistemidir.  
Ã–zellikle rehber Ã¶ÄŸretmenler, psikologlar veya danÄ±ÅŸmanlar iÃ§in geliÅŸtirilmiÅŸtir.

---

##  Ã–zellikler

-  **CanlÄ± Ses Analizi** (WhisperX ile):  
  Ses verileri anlÄ±k olarak yazÄ±ya Ã§evrilir.

-  **Duygu SÄ±nÄ±flandÄ±rmasÄ±** (BERT & RoBERTa):  
  Her 2 cÃ¼mlede bir duygu analizi yapÄ±lÄ±r.  
  14 duygu ve durum kategorisi:
  - `Ã¼zÃ¼ntÃ¼`, `Ã¶fke`, `umutlu`, `stres`, `intihar_dÃ¼ÅŸÃ¼ncesi`, `anksiyete`, `hakaret`, `nefret_sÃ¶ylemi`, `tehdit`, `sevinÃ§`, `normal`, `gÃ¼vensiz`, `kiÅŸilik_boÌ‡zukluÄŸu`, `ruh_hali_salÄ±nÄ±mÄ±`

-  **Duygu KombinasyonlarÄ± TanÄ±ma**:  
  Birden fazla duygu aynÄ± anda analiz edilir ve Ã¶zel Ã¶neriler sunulur.

-  **CanlÄ± Ã–neri Ãœretimi**:  
  Ã–rneÄŸin:  
  `"DanÄ±ÅŸan anksiyete + stres + gÃ¼vensizlik kombinasyonu sergiliyor. SakinleÅŸtirici bir dil kullanÄ±n, gÃ¼ven duygusu oluÅŸturmaya odaklanÄ±n."`

-  **KonuÅŸmacÄ± AyrÄ±mÄ± (Ä°steÄŸe BaÄŸlÄ±)**:  
  `pyannote-audio` ile konuÅŸmacÄ± A (Ã¶ÄŸretmen/danÄ±ÅŸman) ve B (Ã¶ÄŸrenci/danÄ±ÅŸan) ayÄ±rt edilebilir.

---

##  KullanÄ±lan Teknolojiler

| Teknoloji         | AÃ§Ä±klama                                               |
|------------------|--------------------------------------------------------|
| `WhisperX`        | Ses transkripsiyonu ve VAD (Voice Activity Detection) |
| `HuggingFace Transformers` | BERT, RoBERTa modelleriyle duygu tahmini         |
| `PyTorch`         | Model Ã§alÄ±ÅŸtÄ±rma                                       |
| `pyannote-audio`  | KonuÅŸmacÄ± tanÄ±ma (opsiyonel)                           |
| `Scikit-learn`    | Veri iÅŸleme ve doÄŸruluk hesaplama                      |

---

## ğŸ“‚ Proje YapÄ±sÄ±

DataCleaningAndTokenization 

amodel_train_berts 

data_augmentation_and_balance 

final_out_GAN

model_train_robertaw 
---

## ğŸ§ª Kurulum (Kaggle veya Colab)

1. Python 3.10+ ve aÅŸaÄŸÄ±daki kÃ¼tÃ¼phaneleri yÃ¼kleyin:

```bash
pip install torch torchaudio transformers datasets scipy pyannote.audio==3.3.2 whisperx
HuggingFace eriÅŸim anahtarÄ±nÄ±zÄ± tanÄ±mlayÄ±n:


from huggingface_hub import login
login("your_hf_token")
ğŸ” KullanÄ±m
Ses dosyasÄ±nÄ± yÃ¼kle (.wav)

transcribe_chunks.py dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±r â†’ 30 saniyelik parÃ§alara ayÄ±rÄ±r ve metne Ã§evirir.

analyze_emotions.py ile her parÃ§anÄ±n duygularÄ±nÄ± analiz eder.

Uygulama, her cÃ¼mle kombinasyonu iÃ§in anlÄ±k Ã¶neriler Ã¼retir.

 Uygulama Senaryosu
 Rehber Ã¶ÄŸretmen, danÄ±ÅŸman Ã¶ÄŸrencisiyle sesli gÃ¶rÃ¼ÅŸme yapÄ±yor. Sistem, Ã¶ÄŸrencinin ifadelerini analiz ederek Ã¶ÄŸretmene ÅŸu Ã¶neriyi sunuyor:

"DanÄ±ÅŸanÄ±nÄ±z ÅŸu anda anksiyete ve Ã§aresizlik belirtileri gÃ¶steriyor. 'YalnÄ±z deÄŸilsin, buradayÄ±m' gibi cÃ¼mlelerle destekleyici olun."

 GeliÅŸtirme AÅŸamasÄ±nda Planlananlar
 KonuÅŸmacÄ± ayrÄ±mÄ±
 Duygu kombinasyon Ã¶nerileri
 Grafiksel duygu deÄŸiÅŸim zaman Ã§izgisi
 Geri bildirimli Ã¶ÄŸrenme (Q-learning veya Reinforcement)
 GUI / web panel

